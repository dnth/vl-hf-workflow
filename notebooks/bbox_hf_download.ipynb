{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 16:59:32.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mHugging Face session created\u001b[0m\n",
      "\u001b[32m2024-08-07 16:59:32.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVisual Layer session created\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from vlhf.hugging_face import HuggingFace\n",
    "from vlhf.visual_layer import VisualLayer\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Authentication\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "VL_USER_ID = os.getenv(\"VL_USER_ID\")\n",
    "VL_ENV = os.getenv(\"VL_ENV\")\n",
    "\n",
    "hf = HuggingFace(HF_TOKEN)\n",
    "vl = VisualLayer(VL_USER_ID, VL_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf.download_dataset(\"keremberke/german-traffic-sign-detection\", name=\"full\", image_key=\"image\", bbox_key=\"objects\", bbox_label_names=['animals', 'construction', 'cycles crossing', 'danger', 'no entry', 'pedestrian crossing', 'school crossing', 'snow', 'stop', 'bend', 'bend left', 'bend right', 'give way', 'go left', 'go left or straight', 'go right', 'go right or straight', 'go straight', 'keep left', 'keep right', 'no overtaking', 'no overtaking -trucks-', 'no traffic both ways', 'no trucks', 'priority at next intersection', 'priority road', 'restriction ends', 'restriction ends -overtaking -trucks--', 'restriction ends -overtaking-', 'restriction ends 80', 'road narrows', 'roundabout', 'slippery road', 'speed limit 100', 'speed limit 120', 'speed limit 20', 'speed limit 30', 'speed limit 50', 'speed limit 60', 'speed limit 70', 'speed limit 80', 'traffic signal', 'uneven road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf.download_dataset(\"keremberke/csgo-object-detection\", name=\"full\", \n",
    "#                     image_key=\"image\", \n",
    "#                     bbox_key=\"objects\", \n",
    "#                     bbox_label_names=['ct', 'cthead', 't', 'thead']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 17:00:57.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mDownloading dataset rishitdagli/cppe-5 and saving to local path rishitdagli/cppe-5\u001b[0m\n",
      "\u001b[32m2024-08-07 17:01:03.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mAdding image filename to dataset\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edf6c1671834d51b7a54e7a4b091b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1029 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 17:01:04.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mAdding bbox label name to dataset\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fc2137be454fe7a1a477127473e667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1029 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8721b78152db4a83ba90f311fe6b081f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving images:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf.download_dataset(\"rishitdagli/cppe-5\", \n",
    "                    image_key=\"image\", \n",
    "                    bbox_key=\"objects\", \n",
    "                    bbox_label_names=[\"coverall\", \"face_shield\", \"gloves\", \"goggles\", \"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area': [3796, 1596, 152768, 81002],\n",
       " 'bbox': [[302.0, 109.0, 73.0, 52.0],\n",
       "  [810.0, 100.0, 57.0, 28.0],\n",
       "  [160.0, 31.0, 248.0, 616.0],\n",
       "  [741.0, 68.0, 202.0, 401.0]],\n",
       " 'category': [4, 4, 0, 0],\n",
       " 'category_name': ['mask', 'mask', 'coverall', 'coverall'],\n",
       " 'id': [114, 115, 116, 117]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.dataset[0]['objects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 17:01:21.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mto_vl\u001b[0m:\u001b[36m177\u001b[0m - \u001b[1mPreparing upload to Visual Layer\u001b[0m\n",
      "\u001b[32m2024-08-07 17:01:29.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mCreating dataset: cppe-5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset url: https://app.visual-layer.com/dataset/a330d2aa-549b-11ef-be8d-dacb63a3a95e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 17:01:51.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mDataset cppe-5 successfully created in Visual Layer!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hf.to_vl(vl_session=vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -xvf /home/dnth/Desktop/vl-hf-workflow/notebooks/saved_images/keremberke/csgo-object-detection.tar -C /home/dnth/Desktop/vl-hf-workflow/notebooks/saved_images/keremberke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"saved_images/keremberke/object_annotations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the bounding boxes from the dataframe\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_bounding_boxes_from_df(df):\n",
    "    for filename, group in df.groupby('filename'):\n",
    "        image = Image.open(f\"saved_images/keremberke/{filename}\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        for i, row in group.iterrows():\n",
    "            x, y, w, h = row['col_x'], row['row_y'], row['width'], row['height']\n",
    "            label = row['label']\n",
    "            draw.rectangle([x, y, x+w, y+h], outline=\"red\", width=3)\n",
    "            left, top, right, bottom = draw.textbbox((x, y-10), str(label))\n",
    "            draw.rectangle((left-5, top-5, right+5, bottom+5), fill=\"red\")\n",
    "            draw.text((x, y-10), str(label), fill=\"white\")\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Image: {filename}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_boxes_from_df(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vl-hf-workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
