{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 19:38:03.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mHugging Face session created\u001b[0m\n",
      "\u001b[32m2024-08-07 19:38:03.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVisual Layer session created\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from vlhf.hugging_face import HuggingFace\n",
    "from vlhf.visual_layer import VisualLayer\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Authentication\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "VL_USER_ID = os.getenv(\"VL_USER_ID\")\n",
    "VL_ENV = os.getenv(\"VL_ENV\")\n",
    "\n",
    "hf = HuggingFace(HF_TOKEN)\n",
    "vl = VisualLayer(VL_USER_ID, VL_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf.download_dataset(\"keremberke/german-traffic-sign-detection\", name=\"full\", image_key=\"image\", bbox_key=\"objects\", bbox_label_names=['animals', 'construction', 'cycles crossing', 'danger', 'no entry', 'pedestrian crossing', 'school crossing', 'snow', 'stop', 'bend', 'bend left', 'bend right', 'give way', 'go left', 'go left or straight', 'go right', 'go right or straight', 'go straight', 'keep left', 'keep right', 'no overtaking', 'no overtaking -trucks-', 'no traffic both ways', 'no trucks', 'priority at next intersection', 'priority road', 'restriction ends', 'restriction ends -overtaking -trucks--', 'restriction ends -overtaking-', 'restriction ends 80', 'road narrows', 'roundabout', 'slippery road', 'speed limit 100', 'speed limit 120', 'speed limit 20', 'speed limit 30', 'speed limit 50', 'speed limit 60', 'speed limit 70', 'speed limit 80', 'traffic signal', 'uneven road'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf.download_dataset(\"keremberke/csgo-object-detection\", name=\"full\", \n",
    "#                     image_key=\"image\", \n",
    "#                     bbox_key=\"objects\", \n",
    "#                     bbox_label_names=['ct', 'cthead', 't', 'thead']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf.download_dataset(\"rishitdagli/cppe-5\", \n",
    "#                     image_key=\"image\", \n",
    "#                     bbox_key=\"objects\", \n",
    "#                     bbox_label_names=[\"coverall\", \"face_shield\", \"gloves\", \"goggles\", \"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf.download_dataset(\"Francesco/apples-fvpl5\", \n",
    "#                     image_key=\"image\", \n",
    "#                     bbox_key=\"objects\", \n",
    "#                     bbox_label_names=[\"apple\", \"damaged_apple\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 19:38:08.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mDownloading dataset Francesco/weed-crop-aerial and saving to local path Francesco/weed-crop-aerial\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c7cc43cb2345aca1673b1c6008dbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5965583bd4a4f3fbad09bbeb2314e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/58.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad637b6afd44f41b951272e1b308f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fd3ba7b36d4baca25574309854a3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/15.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af086928469b4fdda4b0135f61e24914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51afadfe37f643b985e049eabb17c3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0161e5304f24e5f92a6089c9bf47ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 19:38:52.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mAdding image filename to dataset\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8c759db6ea467c93da13d79e68e273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 19:38:53.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mAdding bbox label name to dataset\u001b[0m\n",
      "\u001b[32m2024-08-07 19:38:54.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mis_one_indexed\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mMinimum category label: 1\u001b[0m\n",
      "\u001b[32m2024-08-07 19:38:54.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mis_one_indexed\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mMaximum category label: 2\u001b[0m\n",
      "\u001b[32m2024-08-07 19:38:54.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mis_one_indexed\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mNumber of unique categories: 2\u001b[0m\n",
      "\u001b[32m2024-08-07 19:38:54.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mis_one_indexed\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mDataset appears to be 1-indexed\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6837961342dd43bfa6219bfc93c721d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923f302100244b10acd42209319b94c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving images:   0%|          | 0/1176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf.download_dataset(\"Francesco/weed-crop-aerial\", \n",
    "                    image_key=\"image\", \n",
    "                    bbox_key=\"objects\", \n",
    "                    bbox_label_names=[\"crop\", \"weed\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 19:38:58.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mto_vl\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mPreparing upload to Visual Layer\u001b[0m\n",
      "\u001b[32m2024-08-07 19:39:00.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mCreating dataset: weed-crop-aerial\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset url: https://app.visual-layer.com/dataset/a42f9fe0-54b1-11ef-b422-ea2abd376502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 19:39:33.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mDataset weed-crop-aerial successfully created in Visual Layer!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hf.to_vl(vl_session=vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -xvf /home/dnth/Desktop/vl-hf-workflow/notebooks/saved_images/keremberke/csgo-object-detection.tar -C /home/dnth/Desktop/vl-hf-workflow/notebooks/saved_images/keremberke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"saved_images/keremberke/object_annotations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the bounding boxes from the dataframe\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_bounding_boxes_from_df(df):\n",
    "    for filename, group in df.groupby('filename'):\n",
    "        image = Image.open(f\"saved_images/keremberke/{filename}\")\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        for i, row in group.iterrows():\n",
    "            x, y, w, h = row['col_x'], row['row_y'], row['width'], row['height']\n",
    "            label = row['label']\n",
    "            draw.rectangle([x, y, x+w, y+h], outline=\"red\", width=3)\n",
    "            left, top, right, bottom = draw.textbbox((x, y-10), str(label))\n",
    "            draw.rectangle((left-5, top-5, right+5, bottom+5), fill=\"red\")\n",
    "            draw.text((x, y-10), str(label), fill=\"white\")\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Image: {filename}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_boxes_from_df(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vl-hf-workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
