{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vlhf.hugging_face import HuggingFace\n",
    "from vlhf.visual_layer import VisualLayer\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "VL_USER_ID = os.getenv(\"VL_USER_ID\")\n",
    "VL_ENV = os.getenv(\"VL_ENV\")\n",
    "\n",
    "hf = HuggingFace(HF_TOKEN)\n",
    "vl = VisualLayer(VL_USER_ID, VL_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>paperswithcode_id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visual-layer/oxford-iiit-pet-vl-enriched</td>\n",
       "      <td>visual-layer</td>\n",
       "      <td>b4a703833ecb83ba0e96cbc638f7df7ff3f45ba5</td>\n",
       "      <td>2024-07-04 06:15:06+00:00</td>\n",
       "      <td>2024-07-29 00:51:33+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:image-classification, task_cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visual-layer/imagenet-1k-vl-enriched</td>\n",
       "      <td>visual-layer</td>\n",
       "      <td>45107c4f5a96e9c2e3d6be3d0a3ca2327b5de3e3</td>\n",
       "      <td>2024-07-09 08:56:33+00:00</td>\n",
       "      <td>2024-07-29 00:52:33+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>393</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:object-detection, task_categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juletxara/visual-spatial-reasoning</td>\n",
       "      <td>juletxara</td>\n",
       "      <td>a07bec7a6b1cbf4b5ca3a68bf744e854982b72bd</td>\n",
       "      <td>2022-08-11 12:56:58+00:00</td>\n",
       "      <td>2022-08-11 20:11:21+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:image-classification, annotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albertvillanova/visual-spatial-reasoning</td>\n",
       "      <td>albertvillanova</td>\n",
       "      <td>cbe3e224f1ae99617e6188679175ff4a9751a1e3</td>\n",
       "      <td>2022-12-14 11:31:30+00:00</td>\n",
       "      <td>2022-12-14 11:55:48+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:image-classification, annotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FastJobs/Visual_Emotional_Analysis</td>\n",
       "      <td>FastJobs</td>\n",
       "      <td>31541d6df6c2f5e0b29f0d434327cf02defa83c7</td>\n",
       "      <td>2023-03-03 06:23:19+00:00</td>\n",
       "      <td>2023-03-13 06:31:17+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>272</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:image-classification, language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alitourani/moviefeats_visual</td>\n",
       "      <td>alitourani</td>\n",
       "      <td>ba9c47d7784a83be0c213eee52bed0ea9139deef</td>\n",
       "      <td>2024-05-10 17:16:19+00:00</td>\n",
       "      <td>2024-05-21 20:26:45+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:feature-extraction, task_categ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id           author  \\\n",
       "0  visual-layer/oxford-iiit-pet-vl-enriched     visual-layer   \n",
       "1      visual-layer/imagenet-1k-vl-enriched     visual-layer   \n",
       "2        juletxara/visual-spatial-reasoning        juletxara   \n",
       "3  albertvillanova/visual-spatial-reasoning  albertvillanova   \n",
       "4        FastJobs/Visual_Emotional_Analysis         FastJobs   \n",
       "5              alitourani/moviefeats_visual       alitourani   \n",
       "\n",
       "                                        sha                created_at  \\\n",
       "0  b4a703833ecb83ba0e96cbc638f7df7ff3f45ba5 2024-07-04 06:15:06+00:00   \n",
       "1  45107c4f5a96e9c2e3d6be3d0a3ca2327b5de3e3 2024-07-09 08:56:33+00:00   \n",
       "2  a07bec7a6b1cbf4b5ca3a68bf744e854982b72bd 2022-08-11 12:56:58+00:00   \n",
       "3  cbe3e224f1ae99617e6188679175ff4a9751a1e3 2022-12-14 11:31:30+00:00   \n",
       "4  31541d6df6c2f5e0b29f0d434327cf02defa83c7 2023-03-03 06:23:19+00:00   \n",
       "5  ba9c47d7784a83be0c213eee52bed0ea9139deef 2024-05-10 17:16:19+00:00   \n",
       "\n",
       "              last_modified  private  gated  disabled  downloads  likes  \\\n",
       "0 2024-07-29 00:51:33+00:00    False  False     False        290      4   \n",
       "1 2024-07-29 00:52:33+00:00    False  False     False        393      6   \n",
       "2 2022-08-11 20:11:21+00:00    False  False     False          6      4   \n",
       "3 2022-12-14 11:55:48+00:00    False  False     False          0      4   \n",
       "4 2023-03-13 06:31:17+00:00    False  False     False        272     10   \n",
       "5 2024-05-21 20:26:45+00:00    False  False     False          0      1   \n",
       "\n",
       "  paperswithcode_id                                               tags  \n",
       "0              None  task_categories:image-classification, task_cat...  \n",
       "1              None  task_categories:object-detection, task_categor...  \n",
       "2              None  task_categories:image-classification, annotati...  \n",
       "3              None  task_categories:image-classification, annotati...  \n",
       "4              None  task_categories:image-classification, language...  \n",
       "5              None  task_categories:feature-extraction, task_categ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.list_datasets(search=\"visual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-01 13:25:11.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mDownloading dataset keremberke/construction-safety-object-detection and saving to local path keremberke/construction-safety-object-detection\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db51feff1c784ca5ae772242b2371aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/22.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bc59698d064f9dbf76001892faa932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4665ae56a8d64683aa64c674a615660f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de77552fe6f454f99f7e65f91db0bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/307 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8aa7d2217994309bc9d9292481c1f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/57 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbeb4ba32bd4939865e8d9ce5f218bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/34 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a89db9cbc9f4c478c11c78463742fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc1e8130ef14e4bbe9893ee065a3cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving images:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hf.download_dataset(\"lewtun/dog_food\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"AI-Lab-Makerere/beans\", label_key='labels')\n",
    "# hf.download_dataset(\"nelorth/oxford-flowers\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"TheBirdLegacy/DALL-E-Dogs\", image_key='Images')\n",
    "# hf.download_dataset(\"sivan22/hebrew-handwritten-dataset\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"rishitdagli/cppe-5\")\n",
    "# hf.download_dataset(\"keremberke/valorant-object-detection\", name=\"full\")\n",
    "# hf.download_dataset(\"Francesco/gynecology-mri\")\n",
    "# hf.download_dataset(\"Az-r-ow/chest_xray\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"Simezu/brain-tumour-MRI-scan\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"Matthijs/snacks\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"fcakyon/pokemon-classification\", name=\"full\", image_key=\"image\", label_key=\"labels\")\n",
    "# hf.download_dataset(\"Kaludi/data-csgo-weapon-classification\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"FastJobs/Visual_Emotional_Analysis\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"davanstrien/amazonian_fish_classifier_data\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"szymonrucinski/types-of-film-shots\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"rootstrap-org/waste-classifier\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"williamberman/wikiart\", image_key=\"image\", label_key=\"genre\")\n",
    "# hf.download_dataset(\"Marxulia/asl_sign_languages_alphabets_v02\", image_key=\"image\", label_key=\"label\")\n",
    "\n",
    "hf.download_dataset(\"keremberke/construction-safety-object-detection\", name=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-01 13:25:50.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mto_vl\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mPreparing upload to Visual Layer\u001b[0m\n",
      "\u001b[32m2024-08-01 13:25:50.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mCreating dataset: construction-safety-object-detection\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset url: https://app.visual-layer.com/dataset/84681146-4fc6-11ef-a4e6-26d8f114f9b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-01 13:26:00.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mDataset construction-safety-object-detection successfully created in Visual Layer!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hf.to_vl(vl_session=vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (\"Kaludi/data-csgo-weapon-classification\", \"image\", \"label\"),\n",
    "    (\"FastJobs/Visual_Emotional_Analysis\", \"image\", \"label\"),\n",
    "    (\"szymonrucinski/types-of-film-shots\", \"image\", \"label\"),\n",
    "    (\"rootstrap-org/waste-classifier\", \"image\", \"label\"),\n",
    "    (\"williamberman/wikiart\", \"image\", \"genre\"),\n",
    "    (\"Marxulia/asl_sign_languages_alphabets_v02\", \"image\", \"label\")\n",
    "]\n",
    "\n",
    "for dataset_name, image_key, label_key in datasets:\n",
    "    hf.download_dataset(dataset_name, image_key=image_key, label_key=label_key)\n",
    "    hf.to_vl(vl_session=vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vl-hf-workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
