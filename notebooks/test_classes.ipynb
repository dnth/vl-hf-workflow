{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vlhf.hugging_face import HuggingFace\n",
    "from vlhf.visual_layer import VisualLayer\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "VL_USER_ID = os.getenv(\"VL_USER_ID\")\n",
    "VL_ENV = os.getenv(\"VL_ENV\")\n",
    "\n",
    "hf = HuggingFace(HF_TOKEN)\n",
    "vl = VisualLayer(VL_USER_ID, VL_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>sha</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>disabled</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>paperswithcode_id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visual-layer/oxford-iiit-pet-vl-enriched</td>\n",
       "      <td>visual-layer</td>\n",
       "      <td>b4a703833ecb83ba0e96cbc638f7df7ff3f45ba5</td>\n",
       "      <td>2024-07-04 06:15:06+00:00</td>\n",
       "      <td>2024-07-29 00:51:33+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:image-classification, task_cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visual-layer/imagenet-1k-vl-enriched</td>\n",
       "      <td>visual-layer</td>\n",
       "      <td>45107c4f5a96e9c2e3d6be3d0a3ca2327b5de3e3</td>\n",
       "      <td>2024-07-09 08:56:33+00:00</td>\n",
       "      <td>2024-07-29 00:52:33+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>393</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:object-detection, task_categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juletxara/visual-spatial-reasoning</td>\n",
       "      <td>juletxara</td>\n",
       "      <td>a07bec7a6b1cbf4b5ca3a68bf744e854982b72bd</td>\n",
       "      <td>2022-08-11 12:56:58+00:00</td>\n",
       "      <td>2022-08-11 20:11:21+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:image-classification, annotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albertvillanova/visual-spatial-reasoning</td>\n",
       "      <td>albertvillanova</td>\n",
       "      <td>cbe3e224f1ae99617e6188679175ff4a9751a1e3</td>\n",
       "      <td>2022-12-14 11:31:30+00:00</td>\n",
       "      <td>2022-12-14 11:55:48+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:image-classification, annotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FastJobs/Visual_Emotional_Analysis</td>\n",
       "      <td>FastJobs</td>\n",
       "      <td>31541d6df6c2f5e0b29f0d434327cf02defa83c7</td>\n",
       "      <td>2023-03-03 06:23:19+00:00</td>\n",
       "      <td>2023-03-13 06:31:17+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>272</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:image-classification, language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alitourani/moviefeats_visual</td>\n",
       "      <td>alitourani</td>\n",
       "      <td>ba9c47d7784a83be0c213eee52bed0ea9139deef</td>\n",
       "      <td>2024-05-10 17:16:19+00:00</td>\n",
       "      <td>2024-05-21 20:26:45+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>task_categories:feature-extraction, task_categ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id           author  \\\n",
       "0  visual-layer/oxford-iiit-pet-vl-enriched     visual-layer   \n",
       "1      visual-layer/imagenet-1k-vl-enriched     visual-layer   \n",
       "2        juletxara/visual-spatial-reasoning        juletxara   \n",
       "3  albertvillanova/visual-spatial-reasoning  albertvillanova   \n",
       "4        FastJobs/Visual_Emotional_Analysis         FastJobs   \n",
       "5              alitourani/moviefeats_visual       alitourani   \n",
       "\n",
       "                                        sha                created_at  \\\n",
       "0  b4a703833ecb83ba0e96cbc638f7df7ff3f45ba5 2024-07-04 06:15:06+00:00   \n",
       "1  45107c4f5a96e9c2e3d6be3d0a3ca2327b5de3e3 2024-07-09 08:56:33+00:00   \n",
       "2  a07bec7a6b1cbf4b5ca3a68bf744e854982b72bd 2022-08-11 12:56:58+00:00   \n",
       "3  cbe3e224f1ae99617e6188679175ff4a9751a1e3 2022-12-14 11:31:30+00:00   \n",
       "4  31541d6df6c2f5e0b29f0d434327cf02defa83c7 2023-03-03 06:23:19+00:00   \n",
       "5  ba9c47d7784a83be0c213eee52bed0ea9139deef 2024-05-10 17:16:19+00:00   \n",
       "\n",
       "              last_modified  private  gated  disabled  downloads  likes  \\\n",
       "0 2024-07-29 00:51:33+00:00    False  False     False        290      4   \n",
       "1 2024-07-29 00:52:33+00:00    False  False     False        393      6   \n",
       "2 2022-08-11 20:11:21+00:00    False  False     False          6      4   \n",
       "3 2022-12-14 11:55:48+00:00    False  False     False          0      4   \n",
       "4 2023-03-13 06:31:17+00:00    False  False     False        272     10   \n",
       "5 2024-05-21 20:26:45+00:00    False  False     False          0      1   \n",
       "\n",
       "  paperswithcode_id                                               tags  \n",
       "0              None  task_categories:image-classification, task_cat...  \n",
       "1              None  task_categories:object-detection, task_categor...  \n",
       "2              None  task_categories:image-classification, annotati...  \n",
       "3              None  task_categories:image-classification, annotati...  \n",
       "4              None  task_categories:image-classification, language...  \n",
       "5              None  task_categories:feature-extraction, task_categ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.list_datasets(search=\"visual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf.download_dataset(\"lewtun/dog_food\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"AI-Lab-Makerere/beans\", label_key='labels')\n",
    "# hf.download_dataset(\"nelorth/oxford-flowers\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"TheBirdLegacy/DALL-E-Dogs\", image_key='Images')\n",
    "# hf.download_dataset(\"sivan22/hebrew-handwritten-dataset\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"rishitdagli/cppe-5\")\n",
    "# hf.download_dataset(\"keremberke/valorant-object-detection\", name=\"full\")\n",
    "# hf.download_dataset(\"Francesco/gynecology-mri\")\n",
    "# hf.download_dataset(\"Az-r-ow/chest_xray\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"Simezu/brain-tumour-MRI-scan\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"Matthijs/snacks\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"fcakyon/pokemon-classification\", name=\"full\", image_key=\"image\", label_key=\"labels\")\n",
    "# hf.download_dataset(\"Kaludi/data-csgo-weapon-classification\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"FastJobs/Visual_Emotional_Analysis\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"davanstrien/amazonian_fish_classifier_data\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"szymonrucinski/types-of-film-shots\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"rootstrap-org/waste-classifier\", image_key=\"image\", label_key=\"label\")\n",
    "# hf.download_dataset(\"williamberman/wikiart\", image_key=\"image\", label_key=\"genre\")\n",
    "# hf.download_dataset(\"Marxulia/asl_sign_languages_alphabets_v02\", image_key=\"image\", label_key=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf.to_vl(vl_session=vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:37:43.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mDownloading dataset Kaludi/data-csgo-weapon-classification and saving to local path Kaludi/data-csgo-weapon-classification\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2685bf7ce3394868974b884a048ce8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eea591d9184cc79a3d7aed090062bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8d37c3101d4306a6acdc51f3b036e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7564d1f4e6d643229f0cb47d3f300881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1650 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bec11142c341d9b48e03283c9c8703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1650 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a0009625c24ea6a04e11e6693b6b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving images:   0%|          | 0/1650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:37:59.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mto_vl\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mPreparing upload to Visual Layer\u001b[0m\n",
      "\u001b[32m2024-07-31 21:37:59.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mCreating dataset: data-csgo-weapon-classification\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset url: https://app.visual-layer.com/dataset/1a78584c-4f42-11ef-9054-7e1db6b41710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:38:27.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mDataset data-csgo-weapon-classification successfully created in Visual Layer!\u001b[0m\n",
      "\u001b[32m2024-07-31 21:38:27.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mDownloading dataset FastJobs/Visual_Emotional_Analysis and saving to local path FastJobs/Visual_Emotional_Analysis\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e38a07e4c8646ba9178cd7e41f111fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c892b244494980a206083a0d96830a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bf5fe7e17847deb9219847950053f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c496f775b741bab5dc64e38cce84b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving images:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:38:33.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mto_vl\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mPreparing upload to Visual Layer\u001b[0m\n",
      "\u001b[32m2024-07-31 21:38:33.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mCreating dataset: Visual_Emotional_Analysis\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset url: https://app.visual-layer.com/dataset/2efbc330-4f42-11ef-8d8b-5e82a4538d0f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:38:38.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mDataset Visual_Emotional_Analysis successfully created in Visual Layer!\u001b[0m\n",
      "\u001b[32m2024-07-31 21:38:38.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mDownloading dataset rootstrap-org/waste-classifier and saving to local path rootstrap-org/waste-classifier\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16c856876e04f32b82f0d0e4aedbcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dddb90d583445ebddcf9e53c9549ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969f81c0c7724b44bd6990eb240451ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving images:   0%|          | 0/3261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnth/anaconda3/envs/vl-hf-workflow/lib/python3.11/site-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-07-31 21:40:55.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mto_vl\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mPreparing upload to Visual Layer\u001b[0m\n",
      "\u001b[32m2024-07-31 21:40:56.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mCreating dataset: waste-classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset url: https://app.visual-layer.com/dataset/83e3adcc-4f42-11ef-ab8c-7e1db6b41710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:43:29.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mDataset waste-classifier successfully created in Visual Layer!\u001b[0m\n",
      "\u001b[32m2024-07-31 21:43:29.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mDownloading dataset williamberman/wikiart and saving to local path williamberman/wikiart\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44c5b9d51084a89a4ead673befb785a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80da1ba51e304e69b542e401a1b924bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/5.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535caeb72e414c1fb6732e1c76e5ff02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/522M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96a502ec6cb45b29b4d96c31db480c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a59e2684c14468b3cc624f41cbf631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dde4a29a3244e798728d97f84263e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2e30267d994c65a13c499af5121595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving images:   0%|          | 0/1132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:45:08.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mto_vl\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mPreparing upload to Visual Layer\u001b[0m\n",
      "\u001b[32m2024-07-31 21:45:08.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mCreating dataset: wikiart\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset url: https://app.visual-layer.com/dataset/1a7bb39c-4f43-11ef-ab8c-7e1db6b41710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:48:07.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mDataset wikiart successfully created in Visual Layer!\u001b[0m\n",
      "\u001b[32m2024-07-31 21:48:07.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mdownload_dataset\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mDownloading dataset Marxulia/asl_sign_languages_alphabets_v02 and saving to local path Marxulia/asl_sign_languages_alphabets_v02\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4ce464a99f4d1a85343dc50313ef9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/887 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5bb74b1d4c4bfb826b3d1d00b4a011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.49M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31afa7831f734149a23c540932cb46ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512a0acd4d8745e0b609607bc65c9831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0e2d6da25e477b84b1cf83deced0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7197063c8881457ca53a8a080bf70116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving images:   0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:48:15.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.hugging_face\u001b[0m:\u001b[36mto_vl\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mPreparing upload to Visual Layer\u001b[0m\n",
      "\u001b[32m2024-07-31 21:48:15.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mCreating dataset: asl_sign_languages_alphabets_v02\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset url: https://app.visual-layer.com/dataset/89e37e90-4f43-11ef-8d8b-5e82a4538d0f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-31 21:48:21.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvlhf.visual_layer\u001b[0m:\u001b[36mcreate_dataset\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mDataset asl_sign_languages_alphabets_v02 successfully created in Visual Layer!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    (\"Kaludi/data-csgo-weapon-classification\", \"image\", \"label\"),\n",
    "    (\"FastJobs/Visual_Emotional_Analysis\", \"image\", \"label\"),\n",
    "    # (\"szymonrucinski/types-of-film-shots\", \"image\", \"label\"),\n",
    "    (\"rootstrap-org/waste-classifier\", \"image\", \"label\"),\n",
    "    (\"williamberman/wikiart\", \"image\", \"genre\"),\n",
    "    (\"Marxulia/asl_sign_languages_alphabets_v02\", \"image\", \"label\")\n",
    "]\n",
    "\n",
    "for dataset_name, image_key, label_key in datasets:\n",
    "    hf.download_dataset(dataset_name, image_key=image_key, label_key=label_key)\n",
    "    hf.to_vl(vl_session=vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vl-hf-workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
